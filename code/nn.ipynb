{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:01:10.523476Z",
     "start_time": "2023-10-25T20:01:10.506461Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:01:10.666590Z",
     "start_time": "2023-10-25T20:01:10.662587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# make sure GPU is available\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:01:10.825735Z",
     "start_time": "2023-10-25T20:01:10.813724Z"
    }
   },
   "outputs": [],
   "source": [
    "# memory management of GPU\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:02:10.558642Z",
     "start_time": "2023-10-25T20:01:35.594257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[catheterization, laboratory, event, hospital,...</td>\n",
       "      <td>3</td>\n",
       "      <td>catheterization laboratory event hospital outc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[renal, abscess, child, three, renal, abscess,...</td>\n",
       "      <td>4</td>\n",
       "      <td>renal abscess child three renal abscess child ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             cleaned  class  \\\n",
       "0  [catheterization, laboratory, event, hospital,...      3   \n",
       "1  [renal, abscess, child, three, renal, abscess,...      4   \n",
       "\n",
       "                                               words  \n",
       "0  catheterization laboratory event hospital outc...  \n",
       "1  renal abscess child three renal abscess child ...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data, 'converters' turns str dtype -> list\n",
    "df = pd.read_csv('../data/train_cleaned.csv', converters={'cleaned': pd.eval}, index_col='Unnamed: 0')\n",
    "\n",
    "# join lists as single string\n",
    "df['words'] = df.cleaned.apply(lambda x: \" \".join(x))\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:03:05.119475Z",
     "start_time": "2023-10-25T20:03:05.099458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "4    0.332802\n",
       "0    0.219075\n",
       "3    0.211317\n",
       "2    0.133329\n",
       "1    0.103477\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at class distribution\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: Neoplasms\n",
    "- 1: Digestive system diseases\n",
    "- 2: Nervous system diseases\n",
    "- 3: Cardiovascular diseases\n",
    "- 4: General pathological conditions\n",
    "\n",
    "We chose to drop class 4, as the 'general' category hindered our model's ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:03:11.442411Z",
     "start_time": "2023-10-25T20:03:11.437406Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop class 4\n",
    "df2 = df.loc[df['class'] < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:03:11.598391Z",
     "start_time": "2023-10-25T20:03:11.581374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14438, 9633)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes of data\n",
    "df.shape[0], df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This reduced sample size from 14.4k to 9.6k\n",
    "- We feel like this drop was for the best, as it allowed our models to classify documents with much greater accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Look at input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T14:11:01.003967Z",
     "start_time": "2023-10-25T14:11:00.289352Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9633, 27268)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df2.words)\n",
    "\n",
    "# shape of input data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Over 27k unique unigrams in our dataset\n",
    "- This number will change based on params passed into the vectorizer\n",
    "- We used SVD (Singular Value Decomposition) to reduce the dimensionality of our vectorized data, reducing our feature space to around 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:39:35.266492Z",
     "start_time": "2023-10-24T19:39:35.241469Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty df to store NN results and params\n",
    "keras_df = pd.DataFrame(columns=['train_acc', 'train_loss', 'test_acc', 'test_loss', 'num_layers', 'shape', 'optim', \n",
    "                                 'epochs', 'batch_size', 'vec_name', 'vec_feats', 'vec_min', 'vec_max'])\n",
    "keras_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T19:39:35.392483Z",
     "start_time": "2023-10-24T19:39:35.380472Z"
    }
   },
   "outputs": [],
   "source": [
    "# train NN, return acc, loss, and model parameters\n",
    "# def fit_eval(node_list, vectorizer, data=df, results_df=keras_df):\n",
    "\n",
    "#     '''\n",
    "    \n",
    "#     Parameters:\n",
    "#     node_list - a list containing node counts for hidden layers\n",
    "\n",
    "#     Returns:\n",
    "#     results_df - df (passed in) with the results appended from the nn, params of NN also included\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     # split train and test data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data.words, data['class'], test_size=0.2, random_state=0)\n",
    "    \n",
    "#     # preprocess data\n",
    "#     X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "#     X_test = vectorizer.transform(X_test).toarray()\n",
    "    \n",
    "#     # further split the training data into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
    "    \n",
    "#     # one-hot encode our labels\n",
    "#     y_train = to_categorical(y_train)\n",
    "#     y_val = to_categorical(y_val)\n",
    "#     y_test = to_categorical(y_test)\n",
    "    \n",
    "#     # add early stopping -> if model doesn't decrease val_loss every 5 epochs, exit the fitting process\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "\n",
    "#     # create the KerasClassifier, use build_model (defined in cell below) as build function\n",
    "#     nn = KerasClassifier(model=build_model(X_train.shape[1], node_list), epochs=1000, batch_size=32, optimizer=Adam(), \n",
    "#                          validation_split=0.2, verbose=0, loss='categorical_crossentropy', callbacks=[early_stopping])\n",
    "    \n",
    "#     # fit nn\n",
    "#     nn.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
    "    \n",
    "#     # accuracy\n",
    "#     train_acc = nn.score(X_train, y_train)\n",
    "#     test_acc = nn.score(X_test, y_test)\n",
    "    \n",
    "#     # prediction probabilities\n",
    "#     train_preds = nn.predict_proba(X_train)\n",
    "#     test_preds = nn.predict_proba(X_test)\n",
    "    \n",
    "#     # loss\n",
    "#     train_loss = categorical_crossentropy(y_train, train_preds)\n",
    "#     test_loss = categorical_crossentropy(y_test, test_preds)\n",
    "\n",
    "#     # ========================================= get model/vectorizer params =========================================\n",
    "    \n",
    "#     # get number of layers\n",
    "#     num_layers = len(nn.model.layers)\n",
    "\n",
    "#     # get shape of nn\n",
    "#     nn_shape = []\n",
    "#     for i, layer in enumerate(nn.model.layers):\n",
    "# #         if i % 2 == 0:\n",
    "#         nn_shape.append(layer.units)\n",
    "\n",
    "#     # optimizer, epochs, batch_size\n",
    "#     optim = str(nn.optimizer).split()[0].split('.')[-1]\n",
    "#     epochs = nn.current_epoch\n",
    "#     batch_size = nn.batch_size\n",
    "    \n",
    "#     # vectorizer name, some parameters\n",
    "#     vec_name = str(vec)[:-2]\n",
    "#     vec_feats = vectorizer.max_features\n",
    "#     vec_min = vectorizer.min_df\n",
    "#     vec_max = vectorizer.max_df\n",
    "    \n",
    "    \n",
    "#     # append results to the df\n",
    "#     results_df.loc[len(results_df.index)] = [train_acc, train_loss, test_acc, test_loss, num_layers, nn_shape, optim, \n",
    "#                                              epochs, batch_size, vec_name, vec_feats, vec_min, vec_max]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:03:15.937414Z",
     "start_time": "2023-10-25T20:03:15.931408Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to build a keras model\n",
    "def build_model(input_dim, node_list):\n",
    "    '''\n",
    "    Build and return a keras NN with a specified node count for each hidden layer.\n",
    "    \n",
    "    Parameters:\n",
    "    node_list - list where nth index value corresponds to nth hidden layer node count\n",
    "    \n",
    "    Returns:\n",
    "    model - a keras NN\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    \n",
    "    # add Dense hidden layers\n",
    "    for node in node_list:\n",
    "        model.add(Dense(node, activation=relu))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "    # output layer - 4 possible classes\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:03:29.806505Z",
     "start_time": "2023-10-25T20:03:29.796496Z"
    }
   },
   "outputs": [],
   "source": [
    "# global random state for reproducibility\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T18:44:07.962201Z",
     "start_time": "2023-10-25T18:44:01.723421Z"
    }
   },
   "outputs": [],
   "source": [
    "# create our vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2.words, df2['class'], test_size=0.2, random_state=random_state)\n",
    "\n",
    "# LSA\n",
    "svd = TruncatedSVD(n_components=100, random_state=random_state)\n",
    "\n",
    "# vectorize and SVD transform the input data\n",
    "X_train = svd.fit_transform(vectorizer.fit_transform(X_train).toarray())\n",
    "X_test = svd.transform(vectorizer.transform(X_test).toarray())\n",
    "\n",
    "# further split the training df2 into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:04:39.687600Z",
     "start_time": "2023-10-25T20:04:39.622542Z"
    }
   },
   "outputs": [],
   "source": [
    "# add early stopping -> if model doesn't decrease val_loss every 5 epochs, exit the fitting process\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "\n",
    "# create the KerasClassifier, use build_model to create our model\n",
    "nn = KerasClassifier(model=build_model(X_train.shape[1], [100, 100]), epochs=100, batch_size=16, optimizer=Adam(),\n",
    "                     callbacks=[early_stopping], validation_split=0.2, verbose=1, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:05:05.442132Z",
     "start_time": "2023-10-25T20:04:49.133425Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 1.2594 - accuracy: 0.5388 - val_loss: 0.8933 - val_accuracy: 0.7860\n",
      "Epoch 2/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.8133 - accuracy: 0.6945 - val_loss: 0.5497 - val_accuracy: 0.8197\n",
      "Epoch 3/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.7221 - accuracy: 0.7393 - val_loss: 0.5278 - val_accuracy: 0.8256\n",
      "Epoch 4/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.7592 - val_loss: 0.5094 - val_accuracy: 0.8320\n",
      "Epoch 5/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6379 - accuracy: 0.7799 - val_loss: 0.5046 - val_accuracy: 0.8275\n",
      "Epoch 6/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6115 - accuracy: 0.7815 - val_loss: 0.4908 - val_accuracy: 0.8320\n",
      "Epoch 7/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.7808 - val_loss: 0.4859 - val_accuracy: 0.8346\n",
      "Epoch 8/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7996 - val_loss: 0.4779 - val_accuracy: 0.8359\n",
      "Epoch 9/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5852 - accuracy: 0.7912 - val_loss: 0.4747 - val_accuracy: 0.8366\n",
      "Epoch 10/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.8030 - val_loss: 0.4794 - val_accuracy: 0.8353\n",
      "Epoch 11/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7972 - val_loss: 0.4649 - val_accuracy: 0.8359\n",
      "Epoch 12/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.8013 - val_loss: 0.4608 - val_accuracy: 0.8392\n",
      "Epoch 13/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5467 - accuracy: 0.8018 - val_loss: 0.4612 - val_accuracy: 0.8424\n",
      "Epoch 14/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.8039 - val_loss: 0.4635 - val_accuracy: 0.8353\n",
      "Epoch 15/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.8024 - val_loss: 0.4702 - val_accuracy: 0.8262\n",
      "Epoch 16/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.8005 - val_loss: 0.4580 - val_accuracy: 0.8307\n",
      "Epoch 17/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5303 - accuracy: 0.8065 - val_loss: 0.4622 - val_accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.8126 - val_loss: 0.4605 - val_accuracy: 0.8262\n",
      "Epoch 19/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.8138 - val_loss: 0.4687 - val_accuracy: 0.8262\n",
      "Epoch 20/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.8155 - val_loss: 0.4628 - val_accuracy: 0.8314\n",
      "Epoch 21/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.8139 - val_loss: 0.4569 - val_accuracy: 0.8314\n",
      "Epoch 22/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.8126 - val_loss: 0.4612 - val_accuracy: 0.8320\n",
      "Epoch 23/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4988 - accuracy: 0.8189 - val_loss: 0.4618 - val_accuracy: 0.8307\n",
      "Epoch 24/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.8173 - val_loss: 0.4614 - val_accuracy: 0.8243\n",
      "Epoch 25/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.8253 - val_loss: 0.4618 - val_accuracy: 0.8340\n",
      "Epoch 26/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.8222 - val_loss: 0.4603 - val_accuracy: 0.8320\n",
      "Epoch 26: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit nn\n",
    "nn.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
    "\n",
    "# free up GPU memory\n",
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- our best NN achieved a val_loss of about 0.45 with a val_acc of 83.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:05:05.696367Z",
     "start_time": "2023-10-25T20:05:05.444134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 676us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       638\n",
      "           1       0.82      0.78      0.80       304\n",
      "           2       0.72      0.75      0.73       382\n",
      "           3       0.89      0.85      0.87       603\n",
      "\n",
      "    accuracy                           0.82      1927\n",
      "   macro avg       0.81      0.81      0.81      1927\n",
      "weighted avg       0.82      0.82      0.82      1927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = nn.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- noteicably worse recall on classes 1 and 2\n",
    "- will use class_weight to attempt to improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T18:44:56.870457Z",
     "start_time": "2023-10-25T18:44:56.854443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76704828, 1.59358842, 1.24074074, 0.79188078])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what 'balanced' class weights would look like\n",
    "y_train.shape[0] / (4 * np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T18:47:46.206544Z",
     "start_time": "2023-10-25T18:47:46.128474Z"
    }
   },
   "outputs": [],
   "source": [
    "# less-intense class weights than the 'balanced' approach\n",
    "class_weight={0: 0.8, 1: 1.5, 2: 1.2, 3: 0.8}\n",
    "\n",
    "# create the KerasClassifier\n",
    "nn = KerasClassifier(model=build_model(X_train.shape[1], [100, 100]), epochs=100, batch_size=16, optimizer=Adam(), \n",
    "                     callbacks=[early_stopping], class_weight=class_weight, validation_split=0.2, verbose=1, \n",
    "                     loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:06:00.074381Z",
     "start_time": "2023-10-25T20:05:52.530457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4892 - accuracy: 0.8215 - val_loss: 0.4656 - val_accuracy: 0.8288\n",
      "Epoch 2/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4816 - accuracy: 0.8196 - val_loss: 0.4656 - val_accuracy: 0.8340\n",
      "Epoch 3/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.8204 - val_loss: 0.4630 - val_accuracy: 0.8268\n",
      "Epoch 4/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8254 - val_loss: 0.4633 - val_accuracy: 0.8301\n",
      "Epoch 5/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.8246 - val_loss: 0.4672 - val_accuracy: 0.8268\n",
      "Epoch 6/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.8287 - val_loss: 0.4654 - val_accuracy: 0.8307\n",
      "Epoch 7/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.8207 - val_loss: 0.4609 - val_accuracy: 0.8346\n",
      "Epoch 8/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.8245 - val_loss: 0.4618 - val_accuracy: 0.8327\n",
      "Epoch 9/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4698 - accuracy: 0.8266 - val_loss: 0.4721 - val_accuracy: 0.8353\n",
      "Epoch 10/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.8275 - val_loss: 0.4747 - val_accuracy: 0.8230\n",
      "Epoch 11/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4496 - accuracy: 0.8327 - val_loss: 0.4630 - val_accuracy: 0.8294\n",
      "Epoch 12/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.8267 - val_loss: 0.4660 - val_accuracy: 0.8327\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit nn\n",
    "nn.fit(X_train, y_train, validation_data=(X_val, y_val))\n",
    "\n",
    "# free up GPU memory\n",
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T18:48:06.520059Z",
     "start_time": "2023-10-25T18:48:06.263825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 667us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82       638\n",
      "           1       0.75      0.83      0.78       304\n",
      "           2       0.70      0.78      0.74       382\n",
      "           3       0.88      0.86      0.87       603\n",
      "\n",
      "    accuracy                           0.81      1927\n",
      "   macro avg       0.80      0.81      0.80      1927\n",
      "weighted avg       0.82      0.81      0.81      1927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = nn.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class weight did up recall for classes 1 and 2, and kept overall acc very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:06:49.118847Z",
     "start_time": "2023-10-25T20:06:49.101831Z"
    }
   },
   "outputs": [],
   "source": [
    "# build stacking classifier\n",
    "stack = StackingClassifier([\n",
    "    ('logreg', KNeighborsClassifier(n_neighbors=20)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, penalty=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:06:51.424129Z",
     "start_time": "2023-10-25T20:06:49.726655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-46 {color: black;}#sk-container-id-46 pre{padding: 0;}#sk-container-id-46 div.sk-toggleable {background-color: white;}#sk-container-id-46 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-46 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-46 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-46 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-46 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-46 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-46 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-46 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-46 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-46 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-46 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-46 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-46 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-46 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-46 div.sk-item {position: relative;z-index: 1;}#sk-container-id-46 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-46 div.sk-item::before, #sk-container-id-46 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-46 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-46 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-46 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-46 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-46 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-46 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-46 div.sk-label-container {text-align: center;}#sk-container-id-46 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-46 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-46\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;logreg&#x27;, KNeighborsClassifier(n_neighbors=20)),\n",
       "                               (&#x27;lr&#x27;,\n",
       "                                LogisticRegression(max_iter=1000,\n",
       "                                                   penalty=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;logreg&#x27;, KNeighborsClassifier(n_neighbors=20)),\n",
       "                               (&#x27;lr&#x27;,\n",
       "                                LogisticRegression(max_iter=1000,\n",
       "                                                   penalty=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>logreg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=20)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, penalty=None)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('logreg', KNeighborsClassifier(n_neighbors=20)),\n",
       "                               ('lr',\n",
       "                                LogisticRegression(max_iter=1000,\n",
       "                                                   penalty=None))])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "stack.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:06:52.198029Z",
     "start_time": "2023-10-25T20:06:52.088926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8348475016223231, 0.8111053450960042)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get scores\n",
    "stack.score(X_train, y_train), stack.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- our best stacker achieved 81.1% testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual stacking\n",
    "- we are using the prediction probs from our best stacking classifier as input to a NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting ONLY preds from stack into NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:09:10.540155Z",
     "start_time": "2023-10-25T20:09:10.336446Z"
    }
   },
   "outputs": [],
   "source": [
    "# get pred probs from the best StackingClassifier\n",
    "train_preds = stack.predict_proba(X_train)\n",
    "val_preds = stack.predict_proba(X_val)\n",
    "test_preds = stack.predict_proba(X_test)\n",
    "\n",
    "# create the KerasClassifier, input is stacker's preds\n",
    "nn = KerasClassifier(model=build_model(train_preds.shape[1], [100, 100]), epochs=100, batch_size=16,\n",
    "                     optimizer=Adam(), callbacks=[early_stopping],\n",
    "                     validation_split=0.2, verbose=1, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:09:23.499539Z",
     "start_time": "2023-10-25T20:09:10.768999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.8049 - accuracy: 0.7703 - val_loss: 0.6771 - val_accuracy: 0.8210\n",
      "Epoch 2/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.6737 - accuracy: 0.8011 - val_loss: 0.5536 - val_accuracy: 0.8243\n",
      "Epoch 3/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.6275 - accuracy: 0.8129 - val_loss: 0.5625 - val_accuracy: 0.8230\n",
      "Epoch 4/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5927 - accuracy: 0.8235 - val_loss: 0.5508 - val_accuracy: 0.8275\n",
      "Epoch 5/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.8225 - val_loss: 0.5456 - val_accuracy: 0.8249\n",
      "Epoch 6/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5903 - accuracy: 0.8162 - val_loss: 0.5464 - val_accuracy: 0.8268\n",
      "Epoch 7/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5855 - accuracy: 0.8238 - val_loss: 0.5430 - val_accuracy: 0.8301\n",
      "Epoch 8/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5768 - accuracy: 0.8245 - val_loss: 0.5423 - val_accuracy: 0.8236\n",
      "Epoch 9/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5856 - accuracy: 0.8191 - val_loss: 0.5377 - val_accuracy: 0.8262\n",
      "Epoch 10/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.8199 - val_loss: 0.5431 - val_accuracy: 0.8327\n",
      "Epoch 11/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.8217 - val_loss: 0.5384 - val_accuracy: 0.8288\n",
      "Epoch 12/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.5692 - accuracy: 0.8232 - val_loss: 0.5397 - val_accuracy: 0.8294\n",
      "Epoch 13/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5754 - accuracy: 0.8251 - val_loss: 0.5428 - val_accuracy: 0.8327\n",
      "Epoch 14/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5653 - accuracy: 0.8262 - val_loss: 0.5361 - val_accuracy: 0.8320\n",
      "Epoch 15/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5700 - accuracy: 0.8266 - val_loss: 0.5359 - val_accuracy: 0.8301\n",
      "Epoch 16/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5711 - accuracy: 0.8261 - val_loss: 0.5323 - val_accuracy: 0.8307\n",
      "Epoch 17/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5689 - accuracy: 0.8228 - val_loss: 0.5452 - val_accuracy: 0.8288\n",
      "Epoch 18/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5708 - accuracy: 0.8232 - val_loss: 0.5448 - val_accuracy: 0.8314\n",
      "Epoch 19/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5699 - accuracy: 0.8214 - val_loss: 0.5361 - val_accuracy: 0.8307\n",
      "Epoch 20/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5698 - accuracy: 0.8222 - val_loss: 0.5354 - val_accuracy: 0.8294\n",
      "Epoch 21/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.5766 - accuracy: 0.8194 - val_loss: 0.5397 - val_accuracy: 0.8327\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-47 {color: black;}#sk-container-id-47 pre{padding: 0;}#sk-container-id-47 div.sk-toggleable {background-color: white;}#sk-container-id-47 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-47 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-47 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-47 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-47 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-47 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-47 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-47 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-47 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-47 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-47 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-47 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-47 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-47 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-47 div.sk-item {position: relative;z-index: 1;}#sk-container-id-47 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-47 div.sk-item::before, #sk-container-id-47 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-47 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-47 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-47 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-47 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-47 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-47 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-47 div.sk-label-container {text-align: center;}#sk-container-id-47 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-47 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-47\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x000001C3C52ED3F0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C3C53662C0&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=16\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" checked><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x000001C3C52ED3F0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C3C53662C0&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=16\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<keras.engine.sequential.Sequential object at 0x000001C3C52ED3F0>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C3C53662C0>\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=16\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[<keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0>]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit nn\n",
    "nn.fit(train_preds, y_train, validation_data=(val_preds, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- still at an 83% val acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting preds from stack + input data into NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:09:56.197455Z",
     "start_time": "2023-10-25T20:09:56.126270Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine pred probs with input data\n",
    "train_full = np.concatenate((X_train, train_preds), axis=1)\n",
    "val_full = np.concatenate((X_val, val_preds), axis=1)\n",
    "test_full = np.concatenate((X_test, test_preds), axis=1)\n",
    "\n",
    "# create the KerasClassifier, pred probs + input data\n",
    "nn = KerasClassifier(model=build_model(train_full.shape[1], [104, 104]), epochs=100, batch_size=64, optimizer=Adam(), \n",
    "                     callbacks=[early_stopping], validation_split=0.2, verbose=1, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:10:05.351419Z",
     "start_time": "2023-10-25T20:09:56.625342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 3ms/step - loss: 0.9002 - accuracy: 0.7466 - val_loss: 1.0653 - val_accuracy: 0.6154\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.8030 - val_loss: 0.9395 - val_accuracy: 0.6634\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.8112 - val_loss: 0.7961 - val_accuracy: 0.7834\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.8092 - val_loss: 0.6590 - val_accuracy: 0.8191\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.8238 - val_loss: 0.5659 - val_accuracy: 0.8236\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.8248 - val_loss: 0.5300 - val_accuracy: 0.8314\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.8267 - val_loss: 0.5226 - val_accuracy: 0.8301\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.8266 - val_loss: 0.5164 - val_accuracy: 0.8294\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.8271 - val_loss: 0.5123 - val_accuracy: 0.8320\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.8290 - val_loss: 0.5149 - val_accuracy: 0.8320\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.8313 - val_loss: 0.5097 - val_accuracy: 0.8320\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8329 - val_loss: 0.5065 - val_accuracy: 0.8320\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8303 - val_loss: 0.5030 - val_accuracy: 0.8294\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8308 - val_loss: 0.5047 - val_accuracy: 0.8314\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8290 - val_loss: 0.5002 - val_accuracy: 0.8275\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8319 - val_loss: 0.4950 - val_accuracy: 0.8307\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8303 - val_loss: 0.4925 - val_accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8290 - val_loss: 0.4915 - val_accuracy: 0.8327\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8352 - val_loss: 0.4925 - val_accuracy: 0.8327\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8310 - val_loss: 0.4940 - val_accuracy: 0.8314\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8352 - val_loss: 0.4936 - val_accuracy: 0.8314\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8323 - val_loss: 0.4887 - val_accuracy: 0.8353\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8275 - val_loss: 0.4862 - val_accuracy: 0.8327\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8381 - val_loss: 0.4886 - val_accuracy: 0.8359\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8324 - val_loss: 0.4890 - val_accuracy: 0.8288\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8376 - val_loss: 0.4883 - val_accuracy: 0.8301\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8324 - val_loss: 0.4857 - val_accuracy: 0.8281\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8363 - val_loss: 0.4946 - val_accuracy: 0.8320\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8365 - val_loss: 0.4841 - val_accuracy: 0.8314\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8361 - val_loss: 0.4823 - val_accuracy: 0.8307\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8384 - val_loss: 0.4905 - val_accuracy: 0.8301\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8361 - val_loss: 0.4817 - val_accuracy: 0.8307\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8391 - val_loss: 0.4856 - val_accuracy: 0.8294\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8371 - val_loss: 0.4883 - val_accuracy: 0.8314\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.8402 - val_loss: 0.4877 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8366 - val_loss: 0.4834 - val_accuracy: 0.8340\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8357 - val_loss: 0.4973 - val_accuracy: 0.8281\n",
      "Epoch 37: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-48 {color: black;}#sk-container-id-48 pre{padding: 0;}#sk-container-id-48 div.sk-toggleable {background-color: white;}#sk-container-id-48 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-48 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-48 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-48 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-48 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-48 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-48 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-48 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-48 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-48 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-48 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-48 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-48 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-48 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-48 div.sk-item {position: relative;z-index: 1;}#sk-container-id-48 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-48 div.sk-item::before, #sk-container-id-48 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-48 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-48 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-48 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-48 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-48 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-48 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-48 div.sk-label-container {text-align: center;}#sk-container-id-48 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-48 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-48\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x000001C3C533BD60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C3D64FF790&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" checked><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x000001C3C533BD60&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C3D64FF790&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<keras.engine.sequential.Sequential object at 0x000001C3C533BD60>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C3D64FF790>\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[<keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0>]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit nn\n",
    "nn.fit(train_full, y_train, validation_data=(val_full, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- val acc still at 83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### putting residuals from stack into NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:11:07.386122Z",
     "start_time": "2023-10-25T20:11:07.266266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "# convert target vars to one-hot-encoded rows using to_categorical\n",
    "train_residuals = to_categorical(y_train) - train_preds\n",
    "val_residuals = to_categorical(y_val) - val_preds\n",
    "test_residuals = to_categorical(y_test) - test_preds\n",
    "\n",
    "# create the KerasClassifier, use residuals as input data\n",
    "nn = KerasClassifier(model=build_model(train_residuals.shape[1], [64, 64, 32, 32]), epochs=100, batch_size=64, optimizer=Adam(), \n",
    "                     callbacks=[early_stopping], validation_split=0.2, verbose=1, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:11:22.052002Z",
     "start_time": "2023-10-25T20:11:09.649964Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 1s 4ms/step - loss: 1.4124 - accuracy: 0.4682 - val_loss: 1.2376 - val_accuracy: 0.4559\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.7741 - accuracy: 0.7088 - val_loss: 0.9801 - val_accuracy: 0.5837\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8170 - val_loss: 0.5452 - val_accuracy: 0.8418\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8662 - val_loss: 0.2377 - val_accuracy: 0.9371\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9122 - val_loss: 0.0667 - val_accuracy: 0.9909\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.9336 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9395 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9521 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9607 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9637 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9622 - val_loss: 9.5540e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9706 - val_loss: 7.5652e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9747 - val_loss: 6.5821e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9800 - val_loss: 5.1074e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9750 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9810 - val_loss: 2.8227e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9831 - val_loss: 2.6098e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9792 - val_loss: 1.7387e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9787 - val_loss: 1.4102e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 9.4773e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9846 - val_loss: 7.9483e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9865 - val_loss: 6.7707e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9888 - val_loss: 5.7607e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9875 - val_loss: 5.5292e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 4.5237e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9898 - val_loss: 3.6115e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 3.0203e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9893 - val_loss: 2.2591e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 2.4340e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9911 - val_loss: 1.9433e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 1.7942e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 2.0752e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 1.6539e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 1.6675e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9882 - val_loss: 1.2936e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9927 - val_loss: 9.0856e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9946 - val_loss: 9.3363e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 5.9040e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9927 - val_loss: 5.2007e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 4.5867e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 4.9394e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 5.6325e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 4.0290e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9940 - val_loss: 3.4408e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9893 - val_loss: 4.8471e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9929 - val_loss: 6.6966e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9924 - val_loss: 4.1775e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9898 - val_loss: 5.4300e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 6.7756e-06 - val_accuracy: 1.0000\n",
      "Epoch 49: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-49 {color: black;}#sk-container-id-49 pre{padding: 0;}#sk-container-id-49 div.sk-toggleable {background-color: white;}#sk-container-id-49 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-49 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-49 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-49 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-49 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-49 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-49 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-49 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-49 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-49 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-49 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-49 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-49 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-49 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-49 div.sk-item {position: relative;z-index: 1;}#sk-container-id-49 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-49 div.sk-item::before, #sk-container-id-49 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-49 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-49 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-49 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-49 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-49 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-49 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-49 div.sk-label-container {text-align: center;}#sk-container-id-49 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-49 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-49\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x000001C3D64A0160&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C4022FA500&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" checked><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;keras.engine.sequential.Sequential object at 0x000001C3D64A0160&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=&lt;keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C4022FA500&gt;\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0&gt;]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<keras.engine.sequential.Sequential object at 0x000001C3D64A0160>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=<keras.optimizers.optimizer_v2.adam.Adam object at 0x000001C4022FA500>\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[<keras.callbacks.EarlyStopping object at 0x000001C3D792D7E0>]\n",
       "\tvalidation_split=0.2\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit nn\n",
    "nn.fit(train_residuals, y_train, validation_data=(val_residuals, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...\n",
    "- This model achieved 100% accuracy on both training and validation sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-25T20:11:50.778463Z",
     "start_time": "2023-10-25T20:11:50.444288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 761us/step\n",
      "31/31 [==============================] - 0s 801us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train acc, test acc\n",
    "nn.score(train_residuals, y_train), nn.score(test_residuals, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
